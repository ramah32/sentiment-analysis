{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6ef9f-0931-42f0-bf73-509094ef8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"D:/sentiment140/training.1600000.processed.noemoticon.csv\"\n",
    "df = pd.read_csv(dataset_path, encoding='latin-1', header=None)\n",
    "df.columns = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = df[[\"target\", \"text\"]]\n",
    "\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: 1 if x == 4 else 0)\n",
    "df = df.sample(250000, random_state=42)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text.lower())\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return \" \".join([word for word in tokens if word.isalpha() and word not in stop_words])\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"clean_text\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "labels = df[\"target\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=256, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(tokens, maxlen=max_length, padding='post')\n",
    "    prediction = model.predict(padded_sequence)[0, 0]\n",
    "    return \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "\n",
    "print(predict_sentiment(\"I love this phone!\"))\n",
    "print(predict_sentiment(\"I hate this movie!\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
